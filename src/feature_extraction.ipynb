{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 15 user information\n",
    "\n",
    "| No | Attribute |\n",
    "|---:|:---|\n",
    "|  1 | PARTICIPANT_ID |\n",
    "|  2 | USER_ID        |\n",
    "|  3 | DEVICE         |\n",
    "|  4 | SCREEN_HEIGHT  |\n",
    "|  5 | SCREEN_WIDTH   |\n",
    "|  6 | YMD            |\n",
    "|  7 | N_TH_TIME      |\n",
    "|  8 | SESSION_ID     |\n",
    "|  9 | VER_HOR        |\n",
    "| 10 | GAME_NUM       |\n",
    "| 11 | STROKE_NUM     |\n",
    "| 12 | DATA_POINTS    |\n",
    "| 13 | START_TIME     |\n",
    "| 14 | STOP_TIME      |\n",
    "| 15 | STROKE_IDX     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 30 touchalytics features\n",
    "\n",
    "| No | Feature name | Description |\n",
    "|---:|:---|:---|\n",
    "|  1 | INTER_STROKE_TIME     | inter-stroke time [$\\text{ms}$]                                          |\n",
    "|  2 | STROKE_DURATION       | stroke duration [$\\text{ms}$]                                            |\n",
    "|  3 | START_X               | x coordinate at the start point [$\\text{px}$]                            |\n",
    "|  4 | START_Y               | y coordinate at the start point [$\\text{px}$]                            |\n",
    "|  5 | STOP_X                | x coordinate at the stop point [$\\text{px}$]                             |\n",
    "|  6 | STOP_Y                | y coordinate at the stop point [$\\text{px}$]                             |\n",
    "|  7 | LENGTH_2EE            | direct end-to-end distance [$\\text{px}$]                                 |\n",
    "|  8 | MEAN_RESULTANT_LENGTH | mean resultant length                                                    |\n",
    "|  9 | DIRECTION_FLAG        | up/down/eft/right flag                                                   |\n",
    "| 10 | DIRECTION_EE          | direction of end-to-end line [$\\text{rad}$]                              |\n",
    "| 11 | VEL_20                | velocity at the 20% percentile point [$\\text{px}/\\text{ms}$]             |\n",
    "| 12 | VEL_50                | velocity at the 50% percentile point [$\\text{px}/\\text{ms}$]             |\n",
    "| 13 | VEL_80                | velocity at the 80% percentile point [$\\text{px}/\\text{ms}$]             |\n",
    "| 14 | ACC_20                | acceleration at the 20% percentile point [$\\text{px}/\\text{ms}^2$]       |\n",
    "| 15 | ACC_50                | acceleration at the 50% percentile point [$\\text{px}/\\text{ms}^2$]       |\n",
    "| 16 | ACC_80                | acceleration at the 80% percentile point [$\\text{px}/\\text{ms}^2$]       |\n",
    "| 17 | MED_VEL_L3            | median velocity at the last 3 points [$\\text{px}/\\text{ms}$]             |\n",
    "| 18 | LARGEST_DEVIATION_EE  | largest deviation from end-to-end line [$\\text{px}$]                     |\n",
    "| 19 | DEV_20                | deviation from end-to-end line at the 20% percentile point [$\\text{px}$] |\n",
    "| 20 | DEV_50                | deviation from end-to-end line at the 50% percentile point [$\\text{px}$] |\n",
    "| 21 | DEV_80                | deviation from end-to-end line at the 80% percentile point [$\\text{px}$] |\n",
    "| 22 | AVERAGE_DIRECTION     | average direction [$\\text{rad}$]                                         |\n",
    "| 23 | LENGTH_TRJ            | length of trajectory [$\\text{px}$]                                       |\n",
    "| 24 | RATIO_TRJ_2EE         | ratio end-to-end distance and length of trajectory                       |\n",
    "| 25 | AVERAGE_VELOCITY      | average velocity [$\\text{px}/\\text{ms}$]                                 |\n",
    "| 26 | MED_ACC_F5            | median acceleration at the first 5 points [$\\text{px}/\\text{ms}^2$]      |\n",
    "| 27 | MID_PRESSURE          | mid-stroke pressure                                                      |\n",
    "| 28 | MID_AREA              | mid-stroke area covered [$\\text{px}^2$]                                  |\n",
    "| 29 | MID_FINGER_ORIENT     | mid-stroke finger orientation                                            |\n",
    "| 30 | PHONE_ORIENT          | phone orientation (0:portrait, 1:landscape)                              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "PATHs = {\n",
    "    \"rawdata\": \"../data/rawdata.csv\",\n",
    "    \"user_info\": \"../data/user_info.csv\",\n",
    "    \"features\": \"../features/features.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame()\n",
    "COLUMNs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load rawdata.csv, user_info.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = pd.DataFrame()\n",
    "\n",
    "filepath = PATHs[\"rawdata\"]\n",
    "with open(filepath, \"r\") as f:\n",
    "    df_load = pd.read_csv(f)\n",
    "\n",
    "# df_load.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.DataFrame()\n",
    "\n",
    "filepath = PATHs[\"user_info\"]\n",
    "with open(filepath, \"r\") as f:\n",
    "    df_user = pd.read_csv(f)\n",
    "\n",
    "# df_user.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\"STROKE_IDX\", \"USER_ID\", \"SESSION_ID\", \"VER_HOR\", \"GAME_NUM\", \"STROKE_NUM\", \"DATA_POINTS\"]\n",
    "COLUMNs += new_cols\n",
    "\n",
    "df_features[new_cols] = df_load.loc[\n",
    "    ~df_load[\"STROKE_IDX\"].duplicated(),\n",
    "    new_cols\n",
    "    ].reset_index(drop=True).copy()\n",
    "\n",
    "df_features = df_features.sort_values([\"STROKE_IDX\"])\n",
    "\n",
    "# df_features.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\"PARTICIPANT_ID\", \"YMD\", \"DEVICE\", \"SCREEN_HEIGHT\", \"SCREEN_WIDTH\", \"N_TH_TIME\"]\n",
    "COLUMNs += new_cols\n",
    "\n",
    "df_1st = df_user.loc[:, [\"PARTICIPANT_ID\", \"1ST_USER_ID\", \"1ST_YMD\", \"1ST_DEVICE\", \"1ST_SCREEN_HEIGHT\", \"1ST_SCREEN_WIDTH\"]].copy()\n",
    "df_1st = df_1st.rename(columns=lambda s: s.replace(\"1ST_\", \"\"))\n",
    "df_1st[\"N_TH_TIME\"] = 1\n",
    "\n",
    "df_2nd = df_user.loc[:, [\"PARTICIPANT_ID\", \"2ND_USER_ID\", \"2ND_YMD\", \"2ND_DEVICE\", \"2ND_SCREEN_HEIGHT\", \"2ND_SCREEN_WIDTH\"]].copy()\n",
    "df_2nd = df_2nd.rename(columns=lambda s: s.replace(\"2ND_\", \"\"))\n",
    "df_2nd[\"N_TH_TIME\"] = 2\n",
    "\n",
    "df_3rd = df_user.loc[:, [\"PARTICIPANT_ID\", \"3RD_USER_ID\", \"3RD_YMD\", \"3RD_DEVICE\", \"3RD_SCREEN_HEIGHT\", \"3RD_SCREEN_WIDTH\"]].copy()\n",
    "df_3rd = df_3rd.rename(columns=lambda s: s.replace(\"3RD_\", \"\"))\n",
    "df_3rd[\"N_TH_TIME\"] = 3\n",
    "\n",
    "df_merge = pd.concat([df_1st, df_2nd, df_3rd], axis=\"index\").reset_index(drop=True)\n",
    "df_merge = df_merge[df_merge[\"USER_ID\"].notnull()].reset_index(drop=True)\n",
    "df_merge[\"YMD\"] = df_merge[\"YMD\"].astype(int).astype(str)\n",
    "\n",
    "df_features = df_features.merge(df_merge, on=\"USER_ID\", how=\"left\")\n",
    "\n",
    "# df_features.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\"START_TIME\", \"STOP_TIME\"]\n",
    "COLUMNs += new_cols\n",
    "\n",
    "df_tmp1 = df_load[[\"STROKE_IDX\", \"TIMESTAMP\"]].groupby([\"STROKE_IDX\"], as_index=False).min()  # START_TIME\n",
    "df_tmp1.columns = [\"STROKE_IDX\", \"START_TIME\"]\n",
    "df_tmp2 = df_load[[\"STROKE_IDX\", \"TIMESTAMP\"]].groupby([\"STROKE_IDX\"], as_index=False).max()  # STOP_TIME\n",
    "df_tmp2.columns = [\"STROKE_IDX\", \"STOP_TIME\"]\n",
    "\n",
    "df_merge = pd.merge(df_tmp1, df_tmp2, on=\"STROKE_IDX\")\n",
    "df_features = df_features.merge(df_merge, on=\"STROKE_IDX\", how=\"left\")\n",
    "\n",
    "# df_features.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Functions #\n",
    "#############\n",
    "def calc_length(p1, p2):\n",
    "    ret = math.sqrt( math.pow( math.fabs(p2[0]-p1[0]), 2 ) + math.pow( math.fabs(p2[1]-p1[1]), 2 ) )\n",
    "    return ret\n",
    "\n",
    "def calc_updw(p1, p2):\n",
    "    ret = \"up\" if((p2[1]-p1[1]) <= 0) else \"down\"\n",
    "    return ret\n",
    "\n",
    "def calc_lfrt(p1, p2):\n",
    "    ret = \"left\" if((p2[0]-p1[0]) <= 0) else \"right\"\n",
    "    return ret\n",
    "\n",
    "# The velocity between two points\n",
    "def calc_velocity(p1, p2, t1, t2):\n",
    "    length = math.sqrt( math.pow( math.fabs(p2[0]-p1[0]), 2 ) + math.pow( math.fabs(p2[1]-p1[1]), 2 ) )\n",
    "    duration = t2 - t1\n",
    "    try:\n",
    "        ret = (length / duration)\n",
    "    except ZeroDivisionError:\n",
    "        ret = np.nan\n",
    "    return ret\n",
    "\n",
    "# The acceleration between two points\n",
    "def calc_accelerarion(v1, v2, t1, t2):\n",
    "    diff_ver = v2 - v1\n",
    "    duration = t2 - t1\n",
    "    try:\n",
    "        ret = (diff_ver / duration)\n",
    "    except ZeroDivisionError:\n",
    "        ret = np.nan\n",
    "    return ret\n",
    "\n",
    "# The area of the contact ellipse\n",
    "def calc_area(rad_x, rad_y):\n",
    "    return rad_x * rad_y * math.pi\n",
    "\n",
    "# 2-dimensional space\n",
    "#  3 | 4\n",
    "# ------\n",
    "# 2 | 1\n",
    "def calc_angle(p1, p2, sys=\"rad\"):\n",
    "    ret = math.atan2(p2[1] - p1[1], p2[0] - p1[0])\n",
    "    if( sys == \"deg\" ):\n",
    "        ret = ret * ( 180.0 / math.pi )\n",
    "\n",
    "    return ret\n",
    "\n",
    "# Calculate percentiles -> Return two points and a ratio.\n",
    "def calc_percentile( count, perc=0.5, origin=0 ):\n",
    "    ret = None\n",
    "    percentile_point = ( (count-1)*perc ) + origin\n",
    "    point1 = math.floor( percentile_point )\n",
    "    point2 = math.ceil( percentile_point )\n",
    "    if( point1==point2 ):\n",
    "        ret = {\n",
    "            \"p1\": point1, \"w1\": round(0.5, 2),\n",
    "            \"p2\": point2, \"w2\": round(0.5, 2),\n",
    "        }\n",
    "    else:\n",
    "        ret = {\n",
    "            \"p1\": point1, \"w1\": round(1 - ( percentile_point-point1 ), 2),\n",
    "            \"p2\": point2, \"w2\": round(1 - ( point2-percentile_point ), 2),\n",
    "        }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Extract time features\n",
    "- INTER_STROKE_TIME\n",
    "- STROKE_DURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- INTER_STROKE_TIME ---#\n",
    "new_cols = [\"INTER_STROKE_TIME\"]\n",
    "COLUMNs += new_cols\n",
    "\n",
    "df_tmp = df_features[[\"STROKE_IDX\", \"USER_ID\", \"START_TIME\", \"STOP_TIME\"]]\n",
    "list_merge = []  # stroke_index, inter_stroke_time\n",
    "inter_stroke_time = 0\n",
    "pre_stroke = {k: None for k in df_tmp.columns}\n",
    "for idx, dict_stroke in enumerate(df_tmp.to_dict(orient='records')):\n",
    "    if(dict_stroke[\"USER_ID\"] != pre_stroke[\"USER_ID\"]):\n",
    "        inter_stroke_time = 0\n",
    "    else:\n",
    "        inter_stroke_time = dict_stroke[\"START_TIME\"] - pre_stroke[\"STOP_TIME\"]\n",
    "\n",
    "    list_merge.append([dict_stroke[\"STROKE_IDX\"], inter_stroke_time])\n",
    "    pre_stroke.update(dict_stroke)\n",
    "\n",
    "df_merge = pd.DataFrame(data=list_merge, columns=[\"STROKE_IDX\", \"INTER_STROKE_TIME\"])\n",
    "df_features = df_features.merge(df_merge, on=\"STROKE_IDX\", how=\"left\")\n",
    "\n",
    "# df_features.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- STROKE_DURATION ---#\n",
    "new_cols = [\"STROKE_DURATION\"]\n",
    "COLUMNs += new_cols\n",
    "\n",
    "df_features.loc[:, \"STROKE_DURATION\"] = df_features[\"STOP_TIME\"] - df_features[\"START_TIME\"]\n",
    "\n",
    "# df_features.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extract features related to the start and stop points\n",
    "- START_X\n",
    "- START_Y\n",
    "- STOP_X\n",
    "- STOP_Y\n",
    "- LENGTH_2EE\n",
    "- DIRECTION_FLAG\n",
    "- DIRECTION_EE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\n",
    "    \"START_X\", \"START_Y\", \"STOP_X\", \"STOP_Y\",\n",
    "    \"LENGTH_2EE\", \"DIRECTION_FLAG\", \"DIRECTION_EE\"\n",
    "    ]\n",
    "COLUMNs += new_cols\n",
    "\n",
    "list_merge = []  # stroke_index, features\n",
    "\n",
    "arr_user = df_features[\"USER_ID\"].unique()\n",
    "for user_id in arr_user:\n",
    "    list_tmp = []\n",
    "    df_tmp1 = df_features.loc[(df_features[\"USER_ID\"]==user_id), [\"STROKE_IDX\", \"VER_HOR\"]].copy()\n",
    "    df_tmp2 = df_load.loc[(df_load[\"USER_ID\"]==user_id), [\"STROKE_IDX\", \"X_COOR\", \"Y_COOR\"]].copy()\n",
    "\n",
    "    for idx, dict_stroke in enumerate( tqdm(df_tmp1.to_dict(orient='records')) ):\n",
    "        arr_coor = df_tmp2.loc[(df_tmp2[\"STROKE_IDX\"]==dict_stroke[\"STROKE_IDX\"]), [\"X_COOR\", \"Y_COOR\"]].to_numpy()\n",
    "        start_coor = arr_coor[0]\n",
    "        stop_coor  = arr_coor[-1]\n",
    "        start_x = start_coor[0]\n",
    "        start_y = start_coor[1]\n",
    "        stop_x = stop_coor[0]\n",
    "        stop_y = stop_coor[1]\n",
    "        length_2ee = calc_length(start_coor, stop_coor)\n",
    "        direction_flag = calc_updw(start_coor, stop_coor) if(dict_stroke[\"VER_HOR\"] == \"v\") else calc_lfrt(start_coor, stop_coor)\n",
    "        direction_ee = calc_angle(start_coor, stop_coor)\n",
    "\n",
    "        # append\n",
    "        list_tmp.append([\n",
    "            dict_stroke[\"STROKE_IDX\"],\n",
    "            start_x,\n",
    "            start_y,\n",
    "            stop_x,\n",
    "            stop_y,\n",
    "            length_2ee,\n",
    "            direction_flag,\n",
    "            direction_ee\n",
    "            ])\n",
    "\n",
    "    # append\n",
    "    list_merge += list_tmp\n",
    "\n",
    "    del list_tmp, df_tmp1, df_tmp2\n",
    "\n",
    "df_merge = pd.DataFrame(data=list_merge, columns=([\"STROKE_IDX\"]+new_cols))\n",
    "df_features = df_features.merge(df_merge, on=\"STROKE_IDX\", how=\"left\")\n",
    "\n",
    "# df_features.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Extract the other features\n",
    " - MEAN_RESULTANT_LENGTH\n",
    " - VEL_20\n",
    " - VEL_50\n",
    " - VEL_80\n",
    " - ACC_20\n",
    " - ACC_50\n",
    " - ACC_80\n",
    " - MED_VEL_L3\n",
    " - LARGEST_DEVIATION_EE\n",
    " - DEV_20\n",
    " - DEV_50\n",
    " - DEV_80\n",
    " - AVERAGE_DIRECTION\n",
    " - LENGTH_TRJ\n",
    " - RATIO_TRJ_2EE\n",
    " - AVERAGE_VELOCITY\n",
    " - MED_ACC_F5\n",
    " - MID_PRESSURE\n",
    " - MID_AREA\n",
    " - MID_FINGER_ORIENT\n",
    " - PHONE_ORIENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\n",
    "    \"MEAN_RESULTANT_LENGTH\",\n",
    "    \"VEL_20\", \"VEL_50\", \"VEL_80\",\n",
    "    \"ACC_20\", \"ACC_50\", \"ACC_80\",\n",
    "    \"MED_VEL_L3\", \"LARGEST_DEVIATION_EE\",\n",
    "    \"DEV_20\", \"DEV_50\", \"DEV_80\",\n",
    "    \"AVERAGE_DIRECTION\", \"LENGTH_TRJ\", \"RATIO_TRJ_2EE\",\n",
    "    \"AVERAGE_VELOCITY\", \"MED_ACC_F5\", \"MID_PRESSURE\",\n",
    "    \"MID_AREA\", \"MID_FINGER_ORIENT\", \"PHONE_ORIENT\"\n",
    "    ]\n",
    "COLUMNs += new_cols\n",
    "\n",
    "list_merge = []  # stroke_index + features\n",
    "\n",
    "arr_user = df_features[\"USER_ID\"].unique()\n",
    "for user_id in arr_user:\n",
    "    list_tmp = []\n",
    "    df_tmp1 = df_features.loc[(df_features[\"USER_ID\"]==user_id), [\"STROKE_IDX\", \"VER_HOR\"]].copy()\n",
    "    df_tmp2 = df_load.loc[(df_load[\"USER_ID\"]==user_id), [\"STROKE_IDX\", \"DATA_POINTS\", \"POINTS_IDX\", \"TIMESTAMP\", \"X_COOR\", \"Y_COOR\", \"FORCE\", \"X_RADIUS\", \"Y_RADIUS\"]].copy()\n",
    "\n",
    "    for idx, dict_stroke in enumerate( tqdm(df_tmp1.to_dict(orient='records')) ):\n",
    "        list_onestroke = df_tmp2.loc[(df_tmp2[\"STROKE_IDX\"]==dict_stroke[\"STROKE_IDX\"]), :].to_dict(orient='records')\n",
    "\n",
    "        feat_sub = {\n",
    "            \"forces\": [],\n",
    "            \"x_rads\": [],\n",
    "            \"y_rads\": [],\n",
    "            \"vels\": [],\n",
    "            \"accs\": [],\n",
    "            \"devs\": [],\n",
    "            \"cos_sum\": 0,\n",
    "            \"sin_sum\": 0,\n",
    "            \"direction_sum\": 0,\n",
    "            \"length_trj_sum\": 0,\n",
    "        }\n",
    "\n",
    "        # percentile points\n",
    "        strkcount = list_onestroke[0][\"DATA_POINTS\"]\n",
    "        strk_20 = calc_percentile( strkcount, perc=0.2 )\n",
    "        strk_50 = calc_percentile( strkcount, perc=0.5 )\n",
    "        strk_80 = calc_percentile( strkcount, perc=0.8 )\n",
    "\n",
    "        # coordinates and times at the start and stop points\n",
    "        start_coor = np.array([list_onestroke[0][\"X_COOR\"], list_onestroke[0][\"Y_COOR\"]])\n",
    "        start_time = list_onestroke[0][\"TIMESTAMP\"]\n",
    "        stop_coor  = np.array([list_onestroke[-1][\"X_COOR\"], list_onestroke[-1][\"Y_COOR\"]])\n",
    "        stop_time  = list_onestroke[-1][\"TIMESTAMP\"]\n",
    "\n",
    "        #--- Analyze strokes by segment ---#\n",
    "        # Start point\n",
    "        feat_sub[\"forces\"].append(list_onestroke[0][\"FORCE\"])\n",
    "        feat_sub[\"x_rads\"].append(list_onestroke[0][\"X_RADIUS\"])\n",
    "        feat_sub[\"y_rads\"].append(list_onestroke[0][\"Y_RADIUS\"])\n",
    "        feat_sub[\"vels\"].append(0)\n",
    "        feat_sub[\"devs\"].append(0)\n",
    "        feat_sub[\"cos_sum\"] += 0\n",
    "        feat_sub[\"sin_sum\"] += 0\n",
    "        feat_sub[\"direction_sum\"] += 0\n",
    "        feat_sub[\"length_trj_sum\"] += 0\n",
    "\n",
    "        # From the second point to the stop point\n",
    "        for idx in range( strkcount-1 ):\n",
    "            p1 = np.array([list_onestroke[idx][\"X_COOR\"], list_onestroke[idx][\"Y_COOR\"]])\n",
    "            t1 = list_onestroke[idx][\"TIMESTAMP\"]\n",
    "            p2 = np.array([list_onestroke[(idx+1)][\"X_COOR\"], list_onestroke[(idx+1)][\"Y_COOR\"]])\n",
    "            t2 = list_onestroke[(idx+1)][\"TIMESTAMP\"]\n",
    "\n",
    "            #- Force -#\n",
    "            feat_sub[\"forces\"].append(list_onestroke[(idx+1)][\"FORCE\"])\n",
    "            #- ----- -#\n",
    "\n",
    "            #- Radius -#\n",
    "            feat_sub[\"x_rads\"].append(list_onestroke[(idx+1)][\"X_RADIUS\"])\n",
    "            feat_sub[\"y_rads\"].append(list_onestroke[(idx+1)][\"Y_RADIUS\"])\n",
    "            #- ------ -#\n",
    "\n",
    "            #- Velocity -#\n",
    "            vel = calc_velocity(p1, p2, t1, t2)\n",
    "            feat_sub[\"vels\"].append(vel)\n",
    "            #- -------- -#\n",
    "\n",
    "            #- Deviation -#\n",
    "            vec1 = stop_coor - start_coor\n",
    "            vec2 = p2 - start_coor\n",
    "            if( np.linalg.norm(vec1) != 0 ):\n",
    "                feat_sub[\"devs\"].append( abs( np.cross(vec1, vec2) / np.linalg.norm(vec1) ) )\n",
    "            else:\n",
    "                feat_sub[\"devs\"] = np.nan\n",
    "            #- ---------------------- -#\n",
    "\n",
    "            #- MEAN_RESULTANT_LENGTH 1 -#\n",
    "            rad = calc_angle(p1, p2, sys=\"rad\")\n",
    "            feat_sub[\"cos_sum\"] += math.cos(rad)\n",
    "            feat_sub[\"sin_sum\"] += math.sin(rad)\n",
    "            #- ------------------ -#\n",
    "\n",
    "            #- AVERAGE_DIRECTION 1 -#\n",
    "            feat_sub[\"direction_sum\"] += calc_angle(p1, p2, sys=\"rad\")\n",
    "            #- ----------------------------------------------- -#\n",
    "\n",
    "            #- LENGTH_TRJ 軌跡の長さ -#\n",
    "            feat_sub[\"length_trj_sum\"] += calc_length(p1, p2)\n",
    "            #- -------------------- -#\n",
    "        #--- ----------------------------- ---#\n",
    "\n",
    "        #- Accelerations -#\n",
    "        feat_sub[\"accs\"].append(0)\n",
    "\n",
    "        for idx in range( strkcount-1 ):\n",
    "            v1 = feat_sub[\"vels\"][idx]\n",
    "            t1 = list_onestroke[idx][\"TIMESTAMP\"]\n",
    "            v2 = feat_sub[\"vels\"][(idx+1)]\n",
    "            t2 = list_onestroke[(idx+1)][\"TIMESTAMP\"]\n",
    "            acc = calc_accelerarion(v1, v2, t1, t2)\n",
    "            feat_sub[\"accs\"].append(acc)\n",
    "        #- ------------- -#\n",
    "\n",
    "        # MEAN_RESULTANT_LENGTH\n",
    "        r = math.sqrt( math.pow( feat_sub[\"cos_sum\"], 2 ) + math.pow( feat_sub[\"sin_sum\"], 2 ) )\n",
    "        mean_resultant_length = r / (strkcount-1)\n",
    "        # VEL_20\n",
    "        _vel_1, _vel_2 = 0, 0\n",
    "        _vel_1 = feat_sub[\"vels\"][ strk_20[\"p1\"] ] * strk_20[\"w1\"]\n",
    "        _vel_2 = feat_sub[\"vels\"][ strk_20[\"p2\"] ] * strk_20[\"w2\"]\n",
    "        vel_20 = _vel_1 + _vel_2\n",
    "        # VEL_50\n",
    "        _vel_1, _vel_2 = 0, 0\n",
    "        _vel_1 = feat_sub[\"vels\"][ strk_50[\"p1\"] ] * strk_50[\"w1\"]\n",
    "        _vel_2 = feat_sub[\"vels\"][ strk_50[\"p2\"] ] * strk_50[\"w2\"]\n",
    "        vel_50 = _vel_1 + _vel_2\n",
    "        # VEL_80\n",
    "        _vel_1, _vel_2 = 0, 0\n",
    "        _vel_1 = feat_sub[\"vels\"][ strk_80[\"p1\"] ] * strk_80[\"w1\"]\n",
    "        _vel_2 = feat_sub[\"vels\"][ strk_80[\"p2\"] ] * strk_80[\"w2\"]\n",
    "        vel_80 = _vel_1 + _vel_2\n",
    "        # ACC_20\n",
    "        _acc_1, _acc_2 = 0, 0\n",
    "        _acc_1 = feat_sub[\"accs\"][ strk_20[\"p1\"] ] * strk_20[\"w1\"]\n",
    "        _acc_2 = feat_sub[\"accs\"][ strk_20[\"p2\"] ] * strk_20[\"w2\"]\n",
    "        acc_20 = _acc_1 + _acc_2\n",
    "        # ACC_50\n",
    "        _acc_1, _acc_2 = 0, 0\n",
    "        _acc_1 = feat_sub[\"accs\"][ strk_50[\"p1\"] ] * strk_50[\"w1\"]\n",
    "        _acc_2 = feat_sub[\"accs\"][ strk_50[\"p2\"] ] * strk_50[\"w2\"]\n",
    "        acc_50 = _acc_1 + _acc_2\n",
    "        # ACC_80\n",
    "        _acc_1, _acc_2 = 0, 0\n",
    "        _acc_1 = feat_sub[\"accs\"][ strk_80[\"p1\"] ] * strk_80[\"w1\"]\n",
    "        _acc_2 = feat_sub[\"accs\"][ strk_80[\"p2\"] ] * strk_80[\"w2\"]\n",
    "        acc_80 = _acc_1 + _acc_2\n",
    "        # MED_VEL_L3\n",
    "        med_vel_l3 = np.median(feat_sub[\"vels\"][-3:])\n",
    "        # LARGEST_DEVIATION_EE\n",
    "        try:\n",
    "            largest_deviation_ee = np.nanmax( feat_sub[\"devs\"] )\n",
    "        except:\n",
    "            largest_deviation_ee = np.nan\n",
    "        # DEV_20\n",
    "        try:\n",
    "            _dev_1, _dev_2 = 0, 0\n",
    "            _dev_1 = feat_sub[\"devs\"][ strk_20[\"p1\"] ] * strk_20[\"w1\"]\n",
    "            _dev_2 = feat_sub[\"devs\"][ strk_20[\"p2\"] ] * strk_20[\"w2\"]\n",
    "            dev_20 = _dev_1 + _dev_2\n",
    "        except:\n",
    "            dev_20 = np.nan\n",
    "        # DEV_50\n",
    "        try:\n",
    "            _dev_1, _dev_2 = 0, 0\n",
    "            _dev_1 = feat_sub[\"devs\"][ strk_50[\"p1\"] ] * strk_50[\"w1\"]\n",
    "            _dev_2 = feat_sub[\"devs\"][ strk_50[\"p2\"] ] * strk_50[\"w2\"]\n",
    "            dev_50 = _dev_1 + _dev_2\n",
    "        except:\n",
    "            dev_50 = np.nan\n",
    "        # DEV_80\n",
    "        try:\n",
    "            _dev_1, _dev_2 = 0, 0\n",
    "            _dev_1 = feat_sub[\"devs\"][ strk_80[\"p1\"] ] * strk_80[\"w1\"]\n",
    "            _dev_2 = feat_sub[\"devs\"][ strk_80[\"p2\"] ] * strk_80[\"w2\"]\n",
    "            dev_80 = _dev_1 + _dev_2\n",
    "        except:\n",
    "            dev_80 = np.nan\n",
    "        # AVERAGE_DIRECTION\n",
    "        try:\n",
    "            average_direction = feat_sub[\"direction_sum\"] / (strkcount-1)\n",
    "        except:\n",
    "            average_direction = np.nan\n",
    "        # LENGTH_TRJ\n",
    "        length_trj = feat_sub[\"length_trj_sum\"]\n",
    "        # RATIO_TRJ_2EE\n",
    "        try:\n",
    "            ratio_trj_2ee = feat_sub[\"length_trj_sum\"] / calc_length(start_coor, stop_coor)\n",
    "        except:\n",
    "            ratio_trj_2ee = np.nan\n",
    "        # AVERAGE_VELOCITY\n",
    "        try:\n",
    "            average_velocity = feat_sub[\"length_trj_sum\"] / (stop_time - start_time)\n",
    "        except:\n",
    "            average_velocity = np.nan\n",
    "        # MED_ACC_F5\n",
    "        med_acc_f5 = np.median(feat_sub[\"accs\"][:5])\n",
    "        # MID_PRESSURE\n",
    "        _pres_1, _pres_2 = 0, 0\n",
    "        _pres_1 = feat_sub[\"forces\"][ strk_50[\"p1\"] ] * strk_50[\"w1\"]\n",
    "        _pres_2 = feat_sub[\"forces\"][ strk_50[\"p2\"] ] * strk_50[\"w2\"]\n",
    "        mid_pressure = _pres_1 + _pres_2\n",
    "        # MID_AREA\n",
    "        _rad_x1, _rad_y1, _rad_x2, _rad_y2 = 0, 0, 0, 0\n",
    "        _rad_x1 = feat_sub[\"x_rads\"][ strk_50[\"p1\"] ] * strk_50[\"w1\"]\n",
    "        _rad_y1 = feat_sub[\"y_rads\"][ strk_50[\"p1\"] ] * strk_50[\"w1\"]\n",
    "        _rad_x2 = feat_sub[\"x_rads\"][ strk_50[\"p2\"] ] * strk_50[\"w2\"]\n",
    "        _rad_y2 = feat_sub[\"y_rads\"][ strk_50[\"p2\"] ] * strk_50[\"w2\"]\n",
    "        mid_area = calc_area( (_rad_x1+_rad_x2), (_rad_y1+_rad_y2) )\n",
    "        # MID_FINGER_ORIENT\n",
    "        mid_finger_orient = np.nan\n",
    "        # PHONE_ORIENT\n",
    "        phone_orient = 0\n",
    "\n",
    "        # append\n",
    "        list_tmp .append([\n",
    "            dict_stroke[\"STROKE_IDX\"],\n",
    "            mean_resultant_length,\n",
    "            vel_20,\n",
    "            vel_50,\n",
    "            vel_80,\n",
    "            acc_20,\n",
    "            acc_50,\n",
    "            acc_80,\n",
    "            med_vel_l3,\n",
    "            largest_deviation_ee,\n",
    "            dev_20,\n",
    "            dev_50,\n",
    "            dev_80,\n",
    "            average_direction,\n",
    "            length_trj,\n",
    "            ratio_trj_2ee,\n",
    "            average_velocity,\n",
    "            med_acc_f5,\n",
    "            mid_pressure,\n",
    "            mid_area,\n",
    "            mid_finger_orient,\n",
    "            phone_orient\n",
    "        ])\n",
    "\n",
    "    # append to the list\n",
    "    list_merge += list_tmp\n",
    "\n",
    "    del list_tmp, df_tmp1, df_tmp2\n",
    "\n",
    "df_merge = pd.DataFrame(data=list_merge, columns=([\"STROKE_IDX\"]+new_cols))\n",
    "df_features = df_features.merge(df_merge, on=\"STROKE_IDX\", how=\"left\")\n",
    "\n",
    "# df_features.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output features.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex\n",
    "col_order = [\n",
    "    \"PARTICIPANT_ID\",\n",
    "    \"USER_ID\",\n",
    "    \"DEVICE\",\n",
    "    \"SCREEN_HEIGHT\",\n",
    "    \"SCREEN_WIDTH\",\n",
    "    \"YMD\",\n",
    "    \"N_TH_TIME\",\n",
    "    \"SESSION_ID\",\n",
    "    \"VER_HOR\",\n",
    "    \"GAME_NUM\",\n",
    "    \"STROKE_NUM\",\n",
    "    \"DATA_POINTS\",\n",
    "    \"START_TIME\",\n",
    "    \"STOP_TIME\",\n",
    "    \"STROKE_IDX\",\n",
    "    \"INTER_STROKE_TIME\",\n",
    "    \"STROKE_DURATION\",\n",
    "    \"START_X\",\n",
    "    \"START_Y\",\n",
    "    \"STOP_X\",\n",
    "    \"STOP_Y\",\n",
    "    \"LENGTH_2EE\",\n",
    "    \"MEAN_RESULTANT_LENGTH\",\n",
    "    \"DIRECTION_FLAG\",\n",
    "    \"DIRECTION_EE\",\n",
    "    \"VEL_20\",\n",
    "    \"VEL_50\",\n",
    "    \"VEL_80\",\n",
    "    \"ACC_20\",\n",
    "    \"ACC_50\",\n",
    "    \"ACC_80\",\n",
    "    \"MED_VEL_L3\",\n",
    "    \"LARGEST_DEVIATION_EE\",\n",
    "    \"DEV_20\",\n",
    "    \"DEV_50\",\n",
    "    \"DEV_80\",\n",
    "    \"AVERAGE_DIRECTION\",\n",
    "    \"LENGTH_TRJ\",\n",
    "    \"RATIO_TRJ_2EE\",\n",
    "    \"AVERAGE_VELOCITY\",\n",
    "    \"MED_ACC_F5\",\n",
    "    \"MID_PRESSURE\",\n",
    "    \"MID_AREA\",\n",
    "    \"MID_FINGER_ORIENT\",\n",
    "    \"PHONE_ORIENT\",\n",
    "    ]\n",
    "\n",
    "df_features = df_features.reindex(col_order, axis=\"columns\")\n",
    "\n",
    "# df_features.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.to_csv(PATHs[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
